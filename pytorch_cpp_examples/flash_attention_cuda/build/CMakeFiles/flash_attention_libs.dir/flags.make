# CMAKE generated file: DO NOT EDIT!
# Generated by "Unix Makefiles" Generator, CMake Version 3.26

# compile CUDA with /usr/local/cuda/bin/nvcc
# compile CXX with /usr/bin/c++
CUDA_DEFINES = -DUSE_C10D_GLOO -DUSE_C10D_NCCL -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -Dflash_attention_libs_EXPORTS

CUDA_INCLUDES = --options-file CMakeFiles/flash_attention_libs.dir/includes_CUDA.rsp

CUDA_FLAGS = -gencode arch=compute_80,code=sm_80 -O3 -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -U__CUDA_NO_BFLOAT16_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -std=c++17 -Xcompiler=-fPIC -D_GLIBCXX_USE_CXX11_ABI=1

CXX_DEFINES = -DUSE_C10D_GLOO -DUSE_C10D_NCCL -DUSE_DISTRIBUTED -DUSE_RPC -DUSE_TENSORPIPE -Dflash_attention_libs_EXPORTS

CXX_INCLUDES = -I/home/eikan/local_disk/liaoxuan/flash-attention/csrc/flash_attn -I/home/eikan/local_disk/liaoxuan/flash-attention/csrc/flash_attn/src -I/home/eikan/local_disk/liaoxuan/flash-attention/csrc/cutlass/include -isystem /home/eikan/local_disk/liaoxuan/anaconda3/envs/cuda/lib/python3.9/site-packages/torch/include -isystem /home/eikan/local_disk/liaoxuan/anaconda3/envs/cuda/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include

CXX_FLAGS =  -O3 -std=c++17 -fPIC -D_GLIBCXX_USE_CXX11_ABI=1

